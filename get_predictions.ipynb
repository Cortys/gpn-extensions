{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpn.data.dataset_manager import DatasetManager\n",
    "from gpn.data.dataset_provider import InMemoryDatasetProvider\n",
    "\n",
    "\n",
    "dataset = \"AmazonPhotos\"\n",
    "\n",
    "def load_dataset(dataset):\n",
    "    dataset_provider = InMemoryDatasetProvider(\n",
    "        DatasetManager(\n",
    "            dataset=dataset,\n",
    "            split_no=1,\n",
    "            root=\"./data\",\n",
    "            ood_flag=False,\n",
    "            train_samples_per_class=0.05,\n",
    "            val_samples_per_class=0.15,\n",
    "            test_samples_per_class=0.8,\n",
    "            split=\"random\",\n",
    "            # ood_setting=\"poisoning\",\n",
    "            # ood_type=\"leave_out_classes\",\n",
    "            # ood_num_left_out_classes=-1,\n",
    "            # ood_leave_out_last_classes=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return dataset_provider\n",
    "\n",
    "data = load_dataset(dataset).data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - train_and_eval - No observers have been added to this run\n",
      "INFO - train_and_eval - Running command 'run_experiment'\n",
      "INFO - train_and_eval - Started\n",
      "INFO - root - Received the following configuration:\n",
      "INFO - root - RUN\n",
      "INFO - root - {'experiment_name': 'classification', 'experiment_directory': './saved_experiments', 'reduced_training_metrics': False, 'eval_mode': 'default', 'job': 'predict', 'save_model': True, 'gpu': 0, 'num_inits': 1, 'num_splits': 1, 'log': False, 'debug': True, 'ex_type': 'transductive', 'ood_loc': True, 'ood_loc_only': False, 'ood_edge_perturbations': True, 'ood_isolated_perturbations': False}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - DATA\n",
      "INFO - root - {'to_sparse': False, 'split_no': 1, 'dataset': 'AmazonPhotos', 'root': './data', 'split': 'random', 'train_samples_per_class': 0.05, 'val_samples_per_class': 0.15, 'test_samples_per_class': 0.8, 'ood_flag': False}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - MODEL\n",
      "INFO - root - {'model_name': 'GPN', 'seed': 42, 'init_no': 1, 'dim_hidden': 64, 'dropout_prob': 0.5, 'dropout_prob_adj': 0.0, 'K': 10, 'alpha_teleport': 0.1, 'add_self_loops': True, 'adj_normalization': 'rw', 'sparse_propagation': True, 'radial_layers': 10, 'maf_layers': 0, 'gaussian_layers': 0, 'dim_latent': 16, 'alpha_evidence_scale': 'latent-new', 'entropy_reg': 0.0001, 'flow_weight_decay': 0.0, 'use_batched_flow': True, 'pre_train_mode': 'flow', 'approximate_reg': True, 'loss_reduction': 'sum'}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - TRAINING\n",
      "INFO - root - {'lr': 0.01, 'weight_decay': 0.001, 'epochs': 100000, 'warmup_epochs': 5, 'finetune_epochs': 0, 'stopping_mode': 'default', 'stopping_patience': 50, 'stopping_restore_best': True, 'stopping_metric': 'val_CE', 'stopping_minimize': True}\n",
      "INFO - root - -----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment (model=GPN, dataset=AmazonPhotos, ood_type=None, split=1, init=1, results=./saved_experiments/classification/GPN/74/results_1.json, trained=True, evaluated=False).\n",
      "Completed experiment (model=GPN, dataset=AmazonPhotos, ood_type=None, split=1, init=1, results=./saved_experiments/classification/GPN/74/results_1.json, trained=True, evaluated=False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - train_and_eval - Result: [Prediction(soft=tensor([[6.9633e-03, 6.7221e-02, 9.2044e-03,  ..., 5.8085e-03, 4.4388e-01,\n",
      "         1.6319e-01],\n",
      "        [2.6065e-03, 4.6030e-02, 8.2073e-03,  ..., 2.6013e-03, 1.4444e-01,\n",
      "         6.7511e-02],\n",
      "        [5.5774e-04, 4.2731e-02, 2.2177e-03,  ..., 1.5024e-04, 8.6556e-03,\n",
      "         2.3246e-02],\n",
      "        ...,\n",
      "        [7.1430e-03, 9.8327e-01, 8.1609e-04,  ..., 5.1573e-04, 8.1070e-04,\n",
      "         1.4107e-03],\n",
      "        [7.6392e-04, 9.5423e-03, 9.3789e-01,  ..., 1.2979e-03, 5.3490e-03,\n",
      "         2.7091e-02],\n",
      "        [3.9126e-03, 8.8131e-02, 7.4786e-03,  ..., 1.4017e-03, 1.6701e-01,\n",
      "         9.8231e-02]]), log_soft=tensor([[-4.9671, -2.6998, -4.6881,  ..., -5.1484, -0.8122, -1.8128],\n",
      "        [-5.9497, -3.0785, -4.8027,  ..., -5.9518, -1.9349, -2.6955],\n",
      "        [-7.4916, -3.1528, -6.1113,  ..., -8.8033, -4.7496, -3.7616],\n",
      "        ...,\n",
      "        [-4.9416, -0.0169, -7.1110,  ..., -7.5699, -7.1176, -6.5637],\n",
      "        [-7.1770, -4.6520, -0.0641,  ..., -6.6470, -5.2309, -3.6085],\n",
      "        [-5.5435, -2.4289, -4.8957,  ..., -6.5700, -1.7897, -2.3204]]), aux_soft=None, aux_log_soft=None, hard=tensor([6, 4, 3,  ..., 1, 2, 3]), alpha=tensor([[1.8699e+03, 1.8051e+04, 2.4717e+03,  ..., 1.5598e+03, 1.1920e+05,\n",
      "         4.3822e+04],\n",
      "        [1.7310e+03, 3.0568e+04, 5.4504e+03,  ..., 1.7275e+03, 9.5923e+04,\n",
      "         4.4833e+04],\n",
      "        [9.5812e+02, 7.3406e+04, 3.8096e+03,  ..., 2.5810e+02, 1.4869e+04,\n",
      "         3.9933e+04],\n",
      "        ...,\n",
      "        [1.1650e+04, 1.6037e+06, 1.3310e+03,  ..., 8.4115e+02, 1.3222e+03,\n",
      "         2.3008e+03],\n",
      "        [1.3983e+03, 1.7467e+04, 1.7168e+06,  ..., 2.3758e+03, 9.7910e+03,\n",
      "         4.9589e+04],\n",
      "        [6.9346e+02, 1.5620e+04, 1.3255e+03,  ..., 2.4844e+02, 2.9600e+04,\n",
      "         1.7410e+04]]), alpha_features=None, propagation_weights=None, x_hat=None, logits=None, logits_features=None, latent=tensor([[-0.1027, -0.1168,  0.0397,  ...,  0.0352,  0.0316,  0.1088],\n",
      "        [ 0.1224,  0.0374, -0.0331,  ..., -0.2827, -0.2680, -0.0688],\n",
      "        [-0.0186, -0.0441, -0.0663,  ...,  0.0920,  0.0064, -0.1221],\n",
      "        ...,\n",
      "        [ 0.1050,  0.1366, -0.0956,  ...,  0.2274,  0.2336, -0.0183],\n",
      "        [-0.0233,  0.0082, -0.0599,  ...,  0.0354,  0.0072, -0.1266],\n",
      "        [ 0.0668, -0.0201, -0.2591,  ...,  0.0996,  0.0089, -0.2417]]), latent_node=None, latent_features=tensor([[-0.1027, -0.1168,  0.0397,  ...,  0.0352,  0.0316,  0.1088],\n",
      "        [ 0.1224,  0.0374, -0.0331,  ..., -0.2827, -0.2680, -0.0688],\n",
      "        [-0.0186, -0.0441, -0.0663,  ...,  0.0920,  0.0064, -0.1221],\n",
      "        ...,\n",
      "        [ 0.1050,  0.1366, -0.0956,  ...,  0.2274,  0.2336, -0.0183],\n",
      "        [-0.0233,  0.0082, -0.0599,  ...,  0.0354,  0.0072, -0.1266],\n",
      "        [ 0.0668, -0.0201, -0.2591,  ...,  0.0996,  0.0089, -0.2417]]), hidden=tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0812, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0901, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0269, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0446, 0.0000]]), hidden_features=tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0812, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0901, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0269, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0446, 0.0000]]), var_predicted=None, var=None, softs=None, energy=None, energy_feaures=None, p_c=None, p_u=None, p_uc=None, chi=None, evidence=tensor([ 268522.1875,  664082.0000, 1717846.1250,  ..., 1630971.0000,\n",
      "        1830444.5000,  177229.8281]), evidence_ft=tensor([  17891.3379,  259498.1562, 2389765.7500,  ..., 6577950.0000,\n",
      "         523180.6875,  264158.4375]), evidence_nn=None, evidence_node=None, evidence_per_class=None, evidence_ft_per_class=None, ft_weight=None, nn_weight=None, log_ft=None, log_ft_per_class=tensor([[-13.9565, -12.3743, -11.9136,  ..., -12.6338, -11.6688, -12.7554],\n",
      "        [-15.9792, -14.2653, -13.2181,  ..., -15.5643,  -8.4557, -12.7824],\n",
      "        [-14.6251, -10.7667, -13.3102,  ..., -16.3109, -13.4942,  -9.2987],\n",
      "        ...,\n",
      "        [-12.5797,  -4.5506, -13.2696,  ..., -15.2760, -16.1318, -15.2563],\n",
      "        [-14.6858, -11.4083, -13.9158,  ..., -15.8091, -12.7090,  -7.4009],\n",
      "        [-15.6018, -10.2629, -13.5311,  ..., -17.3061, -14.4132, -13.2752]]), log_nn=None, log_nn_per_class=None, log_node=None, prediction_confidence_aleatoric=tensor([0.4439, 0.6392, 0.9060,  ..., 0.9833, 0.9379, 0.5111]), prediction_confidence_epistemic=tensor([ 119196.4375,  424515.2188, 1556383.5000,  ..., 1603686.1250,\n",
      "        1716757.8750,   90587.1719]), prediction_confidence_structure=None, sample_confidence_aleatoric=tensor([0.4439, 0.6392, 0.9060,  ..., 0.9833, 0.9379, 0.5111]), sample_confidence_aleatoric_entropy=tensor([-1.5172, -1.1754, -0.4393,  ..., -0.1117, -0.3287, -1.4089]), sample_confidence_epistemic=tensor([ 268530.1875,  664090.0000, 1717854.1250,  ..., 1630979.0000,\n",
      "        1830452.5000,  177237.8281]), sample_confidence_epistemic_entropy=tensor([33.8542, 52.8275, 66.4200,  ..., 77.4487, 55.4765, 53.8299]), sample_confidence_structure=None, sample_confidence_features=tensor([  17899.3379,  259506.1562, 2389773.7500,  ..., 6577958.0000,\n",
      "         523188.6875,  264166.4375]), sample_confidence_neighborhood=None, mu_1=None, mu_1p=None, mu_2=None, mu_2p=None, var_1=None, var_1p=None, var_2=None, var_2p=None, log_q=None, log_prior=None, act_vec=None, q=None)]\n",
      "INFO - train_and_eval - Completed after 0:00:01\n",
      "WARNING - train_and_eval - No observers have been added to this run\n",
      "INFO - train_and_eval - Running command 'run_experiment'\n",
      "INFO - train_and_eval - Started\n",
      "INFO - root - Received the following configuration:\n",
      "INFO - root - RUN\n",
      "INFO - root - {'experiment_name': 'classification', 'experiment_directory': './saved_experiments', 'reduced_training_metrics': False, 'eval_mode': 'default', 'job': 'predict', 'save_model': True, 'gpu': 0, 'num_inits': 1, 'num_splits': 1, 'log': False, 'debug': True, 'ex_type': 'transductive', 'ood_loc': True, 'ood_loc_only': False, 'ood_edge_perturbations': True, 'ood_isolated_perturbations': False}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - DATA\n",
      "INFO - root - {'to_sparse': False, 'split_no': 1, 'dataset': 'AmazonPhotos', 'root': './data', 'split': 'random', 'train_samples_per_class': 0.05, 'val_samples_per_class': 0.15, 'test_samples_per_class': 0.8, 'ood_flag': False}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - MODEL\n",
      "INFO - root - {'model_name': 'GPN_LOP', 'seed': 42, 'init_no': 1, 'dim_hidden': 64, 'dropout_prob': 0.5, 'dropout_prob_adj': 0.0, 'K': 10, 'alpha_teleport': 0.1, 'add_self_loops': True, 'sparse_propagation': True, 'sparse_x_prune_threshold': 0.01, 'radial_layers': 10, 'maf_layers': 0, 'gaussian_layers': 0, 'dim_latent': 16, 'alpha_evidence_scale': 'latent-new', 'entropy_reg': 0.0001, 'flow_weight_decay': 0.0, 'use_batched_flow': True, 'pre_train_mode': 'flow', 'approximate_reg': True, 'loss_reduction': 'sum'}\n",
      "INFO - root - -----------------------------------------\n",
      "INFO - root - TRAINING\n",
      "INFO - root - {'lr': 0.01, 'weight_decay': 0.001, 'epochs': 100000, 'warmup_epochs': 5, 'finetune_epochs': 0, 'stopping_mode': 'default', 'stopping_patience': 50, 'stopping_restore_best': True, 'stopping_metric': 'val_CE', 'stopping_minimize': True}\n",
      "INFO - root - -----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment (model=GPN_LOP, dataset=AmazonPhotos, ood_type=None, split=1, init=1, results=./saved_experiments/classification/GPN_LOP/21/results_1.json, trained=True, evaluated=False).\n",
      "Completed experiment (model=GPN_LOP, dataset=AmazonPhotos, ood_type=None, split=1, init=1, results=./saved_experiments/classification/GPN_LOP/21/results_1.json, trained=True, evaluated=False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - train_and_eval - Result: [Prediction(soft=tensor([[2.2804e-03, 5.6618e-02, 1.7264e-03,  ..., 2.9993e-03, 5.0717e-01,\n",
      "         2.0611e-01],\n",
      "        [3.9701e-04, 3.3742e-02, 1.7931e-02,  ..., 4.2209e-03, 1.3675e-01,\n",
      "         1.2849e-02],\n",
      "        [6.8812e-03, 5.4093e-02, 6.7021e-03,  ..., 5.6292e-04, 1.6903e-02,\n",
      "         1.1880e-02],\n",
      "        ...,\n",
      "        [1.8468e-03, 9.9000e-01, 5.6091e-04,  ..., 3.7372e-03, 5.4735e-04,\n",
      "         2.0189e-04],\n",
      "        [1.6320e-01, 2.9940e-02, 7.2458e-01,  ..., 8.0213e-03, 9.7015e-03,\n",
      "         4.5375e-03],\n",
      "        [3.3498e-03, 1.6509e-01, 7.4905e-03,  ..., 6.8993e-03, 2.2861e-01,\n",
      "         9.3803e-02]]), log_soft=tensor([[-6.0834, -2.8714, -6.3617,  ..., -5.8094, -0.6789, -1.5794],\n",
      "        [-7.8315, -3.3890, -4.0212,  ..., -5.4677, -1.9896, -4.3545],\n",
      "        [-4.9790, -2.9170, -5.0053,  ..., -7.4824, -4.0803, -4.4329],\n",
      "        ...,\n",
      "        [-6.2943, -0.0101, -7.4860,  ..., -5.5894, -7.5104, -8.5078],\n",
      "        [-1.8128, -3.5085, -0.3222,  ..., -4.8257, -4.6355, -5.3954],\n",
      "        [-5.6989, -1.8013, -4.8941,  ..., -4.9763, -1.4757, -2.3666]]), aux_soft=None, aux_log_soft=None, hard=tensor([6, 4, 3,  ..., 1, 2, 3]), alpha=tensor([[1.3639e+05, 2.6414e+06, 8.4796e+04,  ..., 1.5070e+05, 3.5291e+07,\n",
      "         1.1323e+07],\n",
      "        [7.6976e+03, 6.8972e+05, 1.0962e+05,  ..., 6.5804e+04, 2.5257e+06,\n",
      "         5.9905e+05],\n",
      "        [5.6844e+05, 4.4603e+06, 2.8617e+05,  ..., 2.5047e+04, 1.4334e+06,\n",
      "         1.7067e+06],\n",
      "        ...,\n",
      "        [4.1067e+05, 9.0767e+08, 1.0998e+05,  ..., 6.2886e+05, 1.7453e+05,\n",
      "         7.3834e+04],\n",
      "        [3.6524e+06, 7.1864e+05, 2.2348e+08,  ..., 1.7510e+05, 2.1920e+05,\n",
      "         1.0565e+05],\n",
      "        [8.3692e+04, 2.4964e+06, 1.3179e+05,  ..., 1.9603e+05, 8.7042e+06,\n",
      "         3.5946e+06]]), alpha_features=tensor([[2.7765e+05, 2.8397e+06, 1.2353e+05,  ..., 2.0627e+05, 1.1389e+07,\n",
      "         2.4338e+07],\n",
      "        [1.6228e+03, 4.7649e+03, 4.3042e+04,  ..., 1.0423e+04, 1.0293e+06,\n",
      "         3.4642e+04],\n",
      "        [5.8790e+05, 2.2458e+06, 1.3142e+05,  ..., 1.9398e+03, 1.3003e+06,\n",
      "         1.9566e+06],\n",
      "        ...,\n",
      "        [2.1504e+04, 7.8521e+07, 3.5450e+04,  ..., 2.0594e+04, 9.0931e+03,\n",
      "         3.5066e+03],\n",
      "        [1.3449e+07, 2.4988e+06, 1.9219e+06,  ..., 2.9624e+04, 2.0279e+05,\n",
      "         1.0519e+05],\n",
      "        [5.4635e+03, 6.6969e+05, 2.3186e+04,  ..., 1.2751e+03, 1.5196e+04,\n",
      "         7.0070e+03]]), propagation_weights=SparseTensor(row=tensor([   0,    0,    0,  ..., 7649, 7649, 7649]),\n",
      "             col=tensor([   0,  593, 1210,  ..., 5707, 7395, 7649]),\n",
      "             val=tensor([0.2311, 0.0232, 0.0646,  ..., 0.0110, 0.0167, 0.2701]),\n",
      "             size=(7650, 7650), nnz=174600, density=0.30%), x_hat=None, logits=None, logits_features=None, latent=tensor([[-0.0018, -0.0145, -0.0413,  ...,  0.0140, -0.0376, -0.0628],\n",
      "        [ 0.1869,  0.1718, -0.1559,  ..., -0.2904, -0.1864, -0.0330],\n",
      "        [ 0.0316,  0.0025, -0.0477,  ...,  0.0201, -0.0536, -0.1119],\n",
      "        ...,\n",
      "        [ 0.0178,  0.1383, -0.1891,  ...,  0.2675,  0.3057, -0.1004],\n",
      "        [ 0.0647,  0.0177,  0.0750,  ...,  0.0858,  0.0033,  0.0110],\n",
      "        [ 0.0967,  0.1339, -0.2782,  ...,  0.0986,  0.0759, -0.3109]]), latent_node=None, latent_features=tensor([[-0.0018, -0.0145, -0.0413,  ...,  0.0140, -0.0376, -0.0628],\n",
      "        [ 0.1869,  0.1718, -0.1559,  ..., -0.2904, -0.1864, -0.0330],\n",
      "        [ 0.0316,  0.0025, -0.0477,  ...,  0.0201, -0.0536, -0.1119],\n",
      "        ...,\n",
      "        [ 0.0178,  0.1383, -0.1891,  ...,  0.2675,  0.3057, -0.1004],\n",
      "        [ 0.0647,  0.0177,  0.0750,  ...,  0.0858,  0.0033,  0.0110],\n",
      "        [ 0.0967,  0.1339, -0.2782,  ...,  0.0986,  0.0759, -0.3109]]), hidden=tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0698, 0.0000, 0.0571],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0144, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1516, 0.0000]]), hidden_features=tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0698, 0.0000, 0.0571],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0144, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1516, 0.0000]]), var_predicted=None, var=None, softs=None, energy=None, energy_feaures=None, p_c=None, p_u=None, p_uc=None, chi=None, evidence=tensor([[6.1354e+07],\n",
      "        [1.1913e+08],\n",
      "        [1.4598e+09],\n",
      "        ...,\n",
      "        [9.1006e+08],\n",
      "        [2.2975e+08],\n",
      "        [2.9331e+07]]), evidence_ft=tensor([5.4204e+07, 2.9356e+06, 4.4092e+09,  ..., 7.8742e+07, 2.3110e+07,\n",
      "        2.1730e+06]), evidence_nn=None, evidence_node=None, evidence_per_class=None, evidence_ft_per_class=None, ft_weight=None, nn_weight=None, log_ft=None, log_ft_per_class=tensor([[ -7.7141,  -5.3890,  -8.5239,  ...,  -8.0113,  -4.0000,  -3.2406],\n",
      "        [-12.8569, -11.7794,  -9.5783,  ..., -10.9965,  -6.4038,  -9.7954],\n",
      "        [ -6.9639,  -5.6236,  -8.4620,  ..., -12.6784,  -6.1701,  -5.7615],\n",
      "        ...,\n",
      "        [-10.2722,  -2.0693,  -9.7723,  ..., -10.3155, -11.1330, -12.0861],\n",
      "        [ -3.8338,  -5.5169,  -5.7794,  ...,  -9.9519,  -8.0283,  -8.6847],\n",
      "        [-11.6425,  -6.8336, -10.1969,  ..., -13.0982, -10.6195, -11.3937]]), log_nn=None, log_nn_per_class=None, log_node=None, prediction_confidence_aleatoric=tensor([0.5072, 0.7449, 0.8617,  ..., 0.9900, 0.7246, 0.2618]), prediction_confidence_epistemic=tensor([3.5291e+07, 1.1051e+08, 1.4465e+09,  ..., 9.0767e+08, 2.2348e+08,\n",
      "        8.5516e+06]), prediction_confidence_structure=None, sample_confidence_aleatoric=tensor([0.5072, 0.7449, 0.8617,  ..., 0.9900, 0.7246, 0.2618]), sample_confidence_aleatoric_entropy=tensor([-1.3456, -0.9083, -0.6112,  ..., -0.0724, -0.9246, -1.6371]), sample_confidence_epistemic=tensor([6.1354e+07, 1.1913e+08, 1.4598e+09,  ..., 9.1006e+08, 2.2975e+08,\n",
      "        2.9331e+07]), sample_confidence_epistemic_entropy=tensor([66.3868, 67.3206, 79.6056,  ..., 85.0890, 73.5743, 60.9617]), sample_confidence_structure=None, sample_confidence_features=tensor([5.4204e+07, 2.9356e+06, 4.4092e+09,  ..., 7.8742e+07, 2.3110e+07,\n",
      "        2.1730e+06]), sample_confidence_neighborhood=None, mu_1=None, mu_1p=None, mu_2=None, mu_2p=None, var_1=None, var_1p=None, var_2=None, var_2p=None, log_q=None, log_prior=None, act_vec=None, q=None)]\n",
      "INFO - train_and_eval - Completed after 0:00:01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import train_and_eval as tae\n",
    "\n",
    "def get_config_name(model):\n",
    "    if model in (\"gpn\", \"gpn_rw\", \"gpn_lop\"):\n",
    "        return \"configs/gpn/classification_gpn_16.yaml\"\n",
    "    return f\"configs/reference/classification_{model}.yaml\"\n",
    "\n",
    "def get_config_updates(model, dataset):\n",
    "    updates = {}\n",
    "    match model:\n",
    "        case \"gpn\":\n",
    "            model_name = \"GPN\"\n",
    "        case \"gpn_rw\":\n",
    "            model_name = \"GPN\"\n",
    "            updates[\"model.adj_normalization\"] = \"rw\"\n",
    "        case \"gpn_lop\":\n",
    "            model_name = \"GPN_LOP\"\n",
    "            updates[\"model.sparse_x_prune_threshold\"] = 0.01\n",
    "        case _:\n",
    "            model_name = model.upper()\n",
    "    \n",
    "    if dataset in (\"AmazonPhotos\", \"AmazonComputers\", \"PubMedFull\"):\n",
    "        updates[\"model.sparse_propagation\"] = True        \n",
    "    \n",
    "    return {\n",
    "        \"model.model_name\": model_name,\n",
    "        \"data.dataset\": dataset,\n",
    "        \"run.num_inits\": 1,\n",
    "        \"run.num_splits\": 1,\n",
    "        \"run.log\": False,\n",
    "        \"run.job\": \"predict\",\n",
    "        **updates\n",
    "    }\n",
    "\n",
    "def get_prediction(model, dataset):\n",
    "    res = tae.ex.run(\n",
    "        named_configs=[get_config_name(model)],\n",
    "        config_updates={\n",
    "            **get_config_updates(model, dataset),\n",
    "            # \"run.reduced_training_metrics\": True,\n",
    "            # \"training.eval_every\": 10,\n",
    "            # \"training.stopping_patience\": 5,\n",
    "            # \"data.split\": \"public\",\n",
    "            # \"run.num_splits\": 1,\n",
    "            # \"model.model_name\": \"GPN_LOP\",\n",
    "            # \"model.sparse_x_prune_threshold\": 0.01,\n",
    "            # \"run.reeval\": True,\n",
    "        },\n",
    "        options={\"--force\": True},\n",
    "    )\n",
    "\n",
    "    assert isinstance(res.result, list) and len(res.result) == 1\n",
    "    return res.result[0]\n",
    "\n",
    "# gpn_rw_pred = get_prediction(\"gpn_rw\", dataset)\n",
    "gpn_lop_pred = get_prediction(\"gpn_lop\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__attrs_attrs__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'act_vec',\n",
       " 'alpha',\n",
       " 'alpha_features',\n",
       " 'aux_log_soft',\n",
       " 'aux_soft',\n",
       " 'chi',\n",
       " 'clone',\n",
       " 'collate',\n",
       " 'energy',\n",
       " 'energy_feaures',\n",
       " 'evidence',\n",
       " 'evidence_ft',\n",
       " 'evidence_ft_per_class',\n",
       " 'evidence_nn',\n",
       " 'evidence_node',\n",
       " 'evidence_per_class',\n",
       " 'ft_weight',\n",
       " 'hard',\n",
       " 'hidden',\n",
       " 'hidden_features',\n",
       " 'latent',\n",
       " 'latent_features',\n",
       " 'latent_node',\n",
       " 'log_ft',\n",
       " 'log_ft_per_class',\n",
       " 'log_nn',\n",
       " 'log_nn_per_class',\n",
       " 'log_node',\n",
       " 'log_prior',\n",
       " 'log_q',\n",
       " 'log_soft',\n",
       " 'logits',\n",
       " 'logits_features',\n",
       " 'mu_1',\n",
       " 'mu_1p',\n",
       " 'mu_2',\n",
       " 'mu_2p',\n",
       " 'nn_weight',\n",
       " 'p_c',\n",
       " 'p_u',\n",
       " 'p_uc',\n",
       " 'prediction_confidence_aleatoric',\n",
       " 'prediction_confidence_epistemic',\n",
       " 'prediction_confidence_structure',\n",
       " 'propagation_weights',\n",
       " 'q',\n",
       " 'sample_confidence_aleatoric',\n",
       " 'sample_confidence_aleatoric_entropy',\n",
       " 'sample_confidence_epistemic',\n",
       " 'sample_confidence_epistemic_entropy',\n",
       " 'sample_confidence_features',\n",
       " 'sample_confidence_neighborhood',\n",
       " 'sample_confidence_structure',\n",
       " 'set_value',\n",
       " 'set_values',\n",
       " 'soft',\n",
       " 'softs',\n",
       " 'to',\n",
       " 'to_dict',\n",
       " 'var',\n",
       " 'var_1',\n",
       " 'var_1p',\n",
       " 'var_2',\n",
       " 'var_2p',\n",
       " 'var_predicted',\n",
       " 'x_hat']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gpn_lop_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def generate_graph(data, preds, name):\n",
    "    edges = data.edge_index.T.numpy()\n",
    "\n",
    "    y = data.y.numpy()\n",
    "\n",
    "    nodes = {\n",
    "        \"true_y\": y,\n",
    "        \"train_mask\": data.train_mask.numpy().astype(int),\n",
    "        \"val_mask\": data.val_mask.numpy().astype(int),\n",
    "        \"test_mask\": data.test_mask.numpy().astype(int),\n",
    "    }\n",
    "\n",
    "    for model, pred in preds.items():\n",
    "        y_pred = pred.hard.numpy()\n",
    "        err = (y != y_pred).astype(int)\n",
    "        pc_aleatoric = pred.prediction_confidence_aleatoric.numpy()\n",
    "        pc_epistemic = pred.prediction_confidence_epistemic.numpy()\n",
    "        sc_aleatoric = pred.sample_confidence_aleatoric.numpy()\n",
    "        sc_aleatoric_entropy = pred.sample_confidence_aleatoric_entropy.numpy()\n",
    "        sc_epistemic = pred.sample_confidence_epistemic.numpy()\n",
    "        sc_epistemic_entropy = pred.sample_confidence_epistemic_entropy.numpy()\n",
    "        nodes[f\"{model}_y\"] = y_pred\n",
    "        nodes[f\"{model}_err\"] = err\n",
    "        nodes[f\"{model}_pc_aleatoric\"] = pc_aleatoric\n",
    "        nodes[f\"{model}_pc_epistemic\"] = pc_epistemic\n",
    "        nodes[f\"{model}_sc_aleatoric\"] = sc_aleatoric\n",
    "        nodes[f\"{model}_sc_aleatoric_entropy\"] = sc_aleatoric_entropy\n",
    "        nodes[f\"{model}_sc_epistemic\"] = sc_epistemic\n",
    "        nodes[f\"{model}_sc_epistemic_entropy\"] = sc_epistemic_entropy\n",
    "\n",
    "    g = nx.Graph()\n",
    "\n",
    "    g.add_nodes_from(range(len(y)))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        node = g.nodes[i]\n",
    "        for k, v in nodes.items():\n",
    "            node[k] = v[i]\n",
    "\n",
    "    g.add_edges_from(edges)\n",
    "\n",
    "    nx.write_graphml(g, f\"{name}.graphml\")\n",
    "\n",
    "    return g\n",
    "\n",
    "g = generate_graph(data, {\n",
    "    \"gpn_rw\": gpn_rw_pred,\n",
    "    \"gpn_lop\": gpn_lop_pred\n",
    "}, f\"graphs/{dataset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
