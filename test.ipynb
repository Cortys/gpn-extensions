{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.datasets as pygd\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "\u001b[2K [Elapsed 0:00:00 | 1.49 it/s] REG: 0.65403, UCE: 1151.37036, train_CE: 1.76393, train_ECE: 0.43378, train_accuracy: 0.22199, train_average_entropy: 1.06049, train_avg_prediction_confidence_aleatoric: 0.65577, train_avg_prediction_confidence_epistemic: 2245.25562, train_avg_sample_confidence_aleatoric: 0.65577, train_avg_sample_confidence_epistemic: 3423.84106, train_avg_sample_confidence_epistemic_entropy: 13.89416, train_avg_sample_confidence_features: 3424.21606, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.94648, train_confidence_aleatoric_apr: 0.22179, train_confidence_aleatoric_auroc: 0.47620, train_confidence_epistemic_apr: 0.26828, train_confidence_epistemic_auroc: 0.58216, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.76763, val_ECE: 0.43476, val_accuracy: 0.22101, val_average_entropy: 1.06050, val_avg_prediction_confidence_aleatoric: 0.65577, val_avg_prediction_confidence_epistemic: 2245.18115, val_avg_sample_confidence_aleatoric: 0.65577, val_avg_sample_confidence_epistemic: 3423.73193, val_avg_sample_confidence_epistemic_entropy: 13.84506, val_avg_sample_confidence_features: 3424.01025, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.94730, val_confidence_aleatoric_apr: 0.18382, val_confidence_aleatoric_auroc: 0.42107, val_confidence_epistemic_apr: 0.24045, val_confidence_epistemic_auroc: 0.54622, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 2/5:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.02 it/s] REG: 0.66930, UCE: 850.29047, train_CE: 1.36031, train_ECE: 0.01272, train_accuracy: 0.53320, train_average_entropy: 1.16515, train_avg_prediction_confidence_aleatoric: 0.54592, train_avg_prediction_confidence_epistemic: 1879.83948, train_avg_sample_confidence_aleatoric: 0.54592, train_avg_sample_confidence_epistemic: 3443.45410, train_avg_sample_confidence_epistemic_entropy: 13.98660, train_avg_sample_confidence_features: 3443.90674, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.77000, train_confidence_aleatoric_apr: 0.50591, train_confidence_aleatoric_auroc: 0.46027, train_confidence_epistemic_apr: 0.55235, train_confidence_epistemic_auroc: 0.53535, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.36532, val_ECE: 0.01330, val_accuracy: 0.53261, val_average_entropy: 1.16516, val_avg_prediction_confidence_aleatoric: 0.54591, val_avg_prediction_confidence_epistemic: 1879.74329, val_avg_sample_confidence_aleatoric: 0.54591, val_avg_sample_confidence_epistemic: 3443.31152, val_avg_sample_confidence_epistemic_entropy: 13.93756, val_avg_sample_confidence_features: 3443.57764, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.77060, val_confidence_aleatoric_apr: 0.51287, val_confidence_aleatoric_auroc: 0.48914, val_confidence_epistemic_apr: 0.56236, val_confidence_epistemic_auroc: 0.56810, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 3/5:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.31 it/s] REG: 0.67394, UCE: 655.70416, train_CE: 1.66260, train_ECE: 0.32970, train_accuracy: 0.53320, train_average_entropy: 0.55573, train_avg_prediction_confidence_aleatoric: 0.86290, train_avg_prediction_confidence_epistemic: 5265.08984, train_avg_sample_confidence_aleatoric: 0.86290, train_avg_sample_confidence_epistemic: 6101.61816, train_avg_sample_confidence_epistemic_entropy: 17.00421, train_avg_sample_confidence_features: 6102.90137, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.68798, train_confidence_aleatoric_apr: 0.51203, train_confidence_aleatoric_auroc: 0.47639, train_confidence_epistemic_apr: 0.55392, train_confidence_epistemic_auroc: 0.54100, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.66773, val_ECE: 0.33029, val_accuracy: 0.53261, val_average_entropy: 0.55574, val_avg_prediction_confidence_aleatoric: 0.86290, val_avg_prediction_confidence_epistemic: 5264.76074, val_avg_sample_confidence_aleatoric: 0.86290, val_avg_sample_confidence_epistemic: 6101.26807, val_avg_sample_confidence_epistemic_entropy: 16.95514, val_avg_sample_confidence_features: 6101.97559, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.68870, val_confidence_aleatoric_apr: 0.52541, val_confidence_aleatoric_auroc: 0.51046, val_confidence_epistemic_apr: 0.56525, val_confidence_epistemic_auroc: 0.57148, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 4/5:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.39 it/s] REG: 0.81886, UCE: 801.64368, train_CE: 1.86950, train_ECE: 0.38924, train_accuracy: 0.53320, train_average_entropy: 0.36662, train_avg_prediction_confidence_aleatoric: 0.92244, train_avg_prediction_confidence_epistemic: 7500.75146, train_avg_sample_confidence_aleatoric: 0.92244, train_avg_sample_confidence_epistemic: 8131.46338, train_avg_sample_confidence_epistemic_entropy: 18.44090, train_avg_sample_confidence_features: 8133.36816, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.67510, train_confidence_aleatoric_apr: 0.51499, train_confidence_aleatoric_auroc: 0.48150, train_confidence_epistemic_apr: 0.55508, train_confidence_epistemic_auroc: 0.54283, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.87423, val_ECE: 0.38982, val_accuracy: 0.53261, val_average_entropy: 0.36663, val_avg_prediction_confidence_aleatoric: 0.92243, val_avg_prediction_confidence_epistemic: 7500.24951, val_avg_sample_confidence_aleatoric: 0.92243, val_avg_sample_confidence_epistemic: 8130.94629, val_avg_sample_confidence_epistemic_entropy: 18.39205, val_avg_sample_confidence_features: 8131.99365, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.67586, val_confidence_aleatoric_apr: 0.52857, val_confidence_aleatoric_auroc: 0.51570, val_confidence_epistemic_apr: 0.56632, val_confidence_epistemic_auroc: 0.57235, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 5/5:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.33 it/s] REG: 0.88792, UCE: 901.58655, train_CE: 1.80450, train_ECE: 0.37896, train_accuracy: 0.53320, train_average_entropy: 0.40840, train_avg_prediction_confidence_aleatoric: 0.91216, train_avg_prediction_confidence_epistemic: 6772.01514, train_avg_sample_confidence_aleatoric: 0.91216, train_avg_sample_confidence_epistemic: 7424.18799, train_avg_sample_confidence_epistemic_entropy: 17.85942, train_avg_sample_confidence_features: 7425.88867, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.67681, train_confidence_aleatoric_apr: 0.51384, train_confidence_aleatoric_auroc: 0.47989, train_confidence_epistemic_apr: 0.55438, train_confidence_epistemic_auroc: 0.54133, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.80857, val_ECE: 0.37954, val_accuracy: 0.53261, val_average_entropy: 0.40841, val_avg_prediction_confidence_aleatoric: 0.91215, val_avg_prediction_confidence_epistemic: 6771.56299, val_avg_sample_confidence_aleatoric: 0.91215, val_avg_sample_confidence_epistemic: 7423.72119, val_avg_sample_confidence_epistemic_entropy: 17.80971, val_avg_sample_confidence_features: 7424.65576, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.67756, val_confidence_aleatoric_apr: 0.52737, val_confidence_aleatoric_auroc: 0.51417, val_confidence_epistemic_apr: 0.56560, val_confidence_epistemic_auroc: 0.57125, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 1/100000:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.48 it/s] REG: 0.85975, UCE: 869.49524, train_CE: 1.38840, train_ECE: 0.18407, train_accuracy: 0.53320, train_average_entropy: 1.47723, train_avg_prediction_confidence_aleatoric: 0.34912, train_avg_prediction_confidence_epistemic: 1204.90637, train_avg_sample_confidence_aleatoric: 0.34912, train_avg_sample_confidence_epistemic: 3451.22168, train_avg_sample_confidence_epistemic_entropy: 12.76311, train_avg_sample_confidence_features: 3451.51953, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.83134, train_confidence_aleatoric_apr: 0.56826, train_confidence_aleatoric_auroc: 0.53001, train_confidence_epistemic_apr: 0.60860, train_confidence_epistemic_auroc: 0.57270, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.39061, val_ECE: 0.18349, val_accuracy: 0.53261, val_average_entropy: 1.47724, val_avg_prediction_confidence_aleatoric: 0.34912, val_avg_prediction_confidence_epistemic: 1204.81128, val_avg_sample_confidence_aleatoric: 0.34912, val_avg_sample_confidence_epistemic: 3451.00952, val_avg_sample_confidence_epistemic_entropy: 12.71393, val_avg_sample_confidence_features: 3450.89575, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.83172, val_confidence_aleatoric_apr: 0.57445, val_confidence_aleatoric_auroc: 0.56035, val_confidence_epistemic_apr: 0.60548, val_confidence_epistemic_auroc: 0.60048, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 2/100000:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.39 it/s] REG: 0.61483, UCE: 668.32819, train_CE: 1.52717, train_ECE: 0.18338, train_accuracy: 0.22199, train_average_entropy: 1.40448, train_avg_prediction_confidence_aleatoric: 0.40538, train_avg_prediction_confidence_epistemic: 1553.56421, train_avg_sample_confidence_aleatoric: 0.40538, train_avg_sample_confidence_epistemic: 3832.41211, train_avg_sample_confidence_epistemic_entropy: 13.18773, train_avg_sample_confidence_features: 3833.54932, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.88682, train_confidence_aleatoric_apr: 0.78565, train_confidence_aleatoric_auroc: 0.91692, train_confidence_epistemic_apr: 0.15916, train_confidence_epistemic_auroc: 0.33812, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.52914, val_ECE: 0.18436, val_accuracy: 0.22101, val_average_entropy: 1.40448, val_avg_prediction_confidence_aleatoric: 0.40537, val_avg_prediction_confidence_epistemic: 1553.52271, val_avg_sample_confidence_aleatoric: 0.40537, val_avg_sample_confidence_epistemic: 3832.31909, val_avg_sample_confidence_epistemic_entropy: 13.13870, val_avg_sample_confidence_features: 3833.25293, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.88722, val_confidence_aleatoric_apr: 0.71257, val_confidence_aleatoric_auroc: 0.89603, val_confidence_epistemic_apr: 0.16910, val_confidence_epistemic_auroc: 0.38190, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 3/100000:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.26 it/s] REG: 0.63541, UCE: 734.44592, train_CE: 1.41438, train_ECE: 0.12562, train_accuracy: 0.22199, train_average_entropy: 1.34688, train_avg_prediction_confidence_aleatoric: 0.34761, train_avg_prediction_confidence_epistemic: 1244.56067, train_avg_sample_confidence_aleatoric: 0.34761, train_avg_sample_confidence_epistemic: 3580.36133, train_avg_sample_confidence_epistemic_entropy: 13.40715, train_avg_sample_confidence_features: 3582.06348, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.85724, train_confidence_aleatoric_apr: 0.88589, train_confidence_aleatoric_auroc: 0.96080, train_confidence_epistemic_apr: 0.14481, train_confidence_epistemic_auroc: 0.26071, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.41664, val_ECE: 0.12659, val_accuracy: 0.22101, val_average_entropy: 1.34688, val_avg_prediction_confidence_aleatoric: 0.34761, val_avg_prediction_confidence_epistemic: 1244.52039, val_avg_sample_confidence_aleatoric: 0.34761, val_avg_sample_confidence_epistemic: 3580.26514, val_avg_sample_confidence_epistemic_entropy: 13.35810, val_avg_sample_confidence_features: 3581.88916, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.85762, val_confidence_aleatoric_apr: 0.79344, val_confidence_aleatoric_auroc: 0.93557, val_confidence_epistemic_apr: 0.15048, val_confidence_epistemic_auroc: 0.30252, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 4/100000:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.33 it/s] REG: 0.64514, UCE: 681.92004, train_CE: 1.27472, train_ECE: 0.03041, train_accuracy: 0.53320, train_average_entropy: 1.21379, train_avg_prediction_confidence_aleatoric: 0.50279, train_avg_prediction_confidence_epistemic: 1683.97998, train_avg_sample_confidence_aleatoric: 0.50279, train_avg_sample_confidence_epistemic: 3349.26611, train_avg_sample_confidence_epistemic_entropy: 13.73591, train_avg_sample_confidence_features: 3351.35229, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.77584, train_confidence_aleatoric_apr: 0.95549, train_confidence_aleatoric_auroc: 0.94980, train_confidence_epistemic_apr: 0.95905, train_confidence_epistemic_auroc: 0.95341, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.27743, val_ECE: 0.02983, val_accuracy: 0.53261, val_average_entropy: 1.21380, val_avg_prediction_confidence_aleatoric: 0.50278, val_avg_prediction_confidence_epistemic: 1683.94006, val_avg_sample_confidence_aleatoric: 0.50278, val_avg_sample_confidence_epistemic: 3349.22217, val_avg_sample_confidence_epistemic_entropy: 13.68683, val_avg_sample_confidence_features: 3351.36914, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.77632, val_confidence_aleatoric_apr: 0.94267, val_confidence_aleatoric_auroc: 0.93356, val_confidence_epistemic_apr: 0.94741, val_confidence_epistemic_auroc: 0.93977, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 5/100000:\n",
      "\u001b[2K [Elapsed 0:00:00 | 2.34 it/s] REG: 0.65978, UCE: 613.95007, train_CE: 1.32945, train_ECE: 0.17169, train_accuracy: 0.53320, train_average_entropy: 0.92694, train_avg_prediction_confidence_aleatoric: 0.70488, train_avg_prediction_confidence_epistemic: 2597.54053, train_avg_sample_confidence_aleatoric: 0.70488, train_avg_sample_confidence_epistemic: 3685.04907, train_avg_sample_confidence_epistemic_entropy: 14.66632, train_avg_sample_confidence_features: 3687.74609, train_avg_sample_confidence_neighborhood: nan, train_brier_score: 0.72011, train_confidence_aleatoric_apr: 0.96425, train_confidence_aleatoric_auroc: 0.95978, train_confidence_epistemic_apr: 0.96378, train_confidence_epistemic_auroc: 0.95735, train_confidence_structure_apr: nan, train_confidence_structure_auroc: nan, val_CE: 1.33246, val_ECE: 0.17227, val_accuracy: 0.53261, val_average_entropy: 0.92695, val_avg_prediction_confidence_aleatoric: 0.70488, val_avg_prediction_confidence_epistemic: 2597.53833, val_avg_sample_confidence_aleatoric: 0.70488, val_avg_sample_confidence_epistemic: 3685.05664, val_avg_sample_confidence_epistemic_entropy: 14.61728, val_avg_sample_confidence_features: 3688.01636, val_avg_sample_confidence_neighborhood: nan, val_brier_score: 0.72073, val_confidence_aleatoric_apr: 0.95690, val_confidence_aleatoric_auroc: 0.94532, val_confidence_epistemic_apr: 0.95555, val_confidence_epistemic_auroc: 0.94554, val_confidence_structure_apr: nan, val_confidence_structure_auroc: nan\n",
      "Epoch 6/100000:\n",
      "\u001b[2K [                              ] (0.0%) ETA n/a [Elapsed 0:00:00 | 0.00 it/s]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# gpn_e = create_experiment(\"GPN\")\u001b[39;00m\n\u001b[1;32m     78\u001b[0m lop_e \u001b[38;5;241m=\u001b[39m create_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPN_LOP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m res_lop \u001b[38;5;241m=\u001b[39m \u001b[43mlop_e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# res = gpn_e.run()\u001b[39;00m\n\u001b[1;32m     81\u001b[0m res_lop\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/experiments/multiple_run_experiment.py:50\u001b[0m, in \u001b[0;36mMultipleRunExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_cfg\u001b[38;5;241m.\u001b[39mset_values(init_no\u001b[38;5;241m=\u001b[39minit_no)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cfg\u001b[38;5;241m.\u001b[39mex_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransductive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_transductive_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/experiments/multiple_run_experiment.py:78\u001b[0m, in \u001b[0;36mMultipleRunExperiment.run_transductive_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_transductive_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     75\u001b[0m     experiment \u001b[38;5;241m=\u001b[39m TransductiveExperiment(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cfg\u001b[38;5;241m.\u001b[39mclone(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cfg\u001b[38;5;241m.\u001b[39mclone(),\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_cfg\u001b[38;5;241m.\u001b[39mclone(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mclone(), ex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mex)\n\u001b[0;32m---> 78\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/experiments/transductive_experiment.py:295\u001b[0m, in \u001b[0;36mTransductiveExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cfg\u001b[38;5;241m.\u001b[39mjob \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cfg\u001b[38;5;241m.\u001b[39mood_flag:\n\u001b[1;32m    298\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_ood()\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/experiments/transductive_experiment.py:251\u001b[0m, in \u001b[0;36mTransductiveExperiment.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optimizer[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# default training\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlikelihood_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlikelihood_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# finetuning\u001b[39;00m\n\u001b[1;32m    266\u001b[0m finetune_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mfinetune_epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mfinetune_epochs\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/nn/transductive_graph_engine.py:140\u001b[0m, in \u001b[0;36mTransductiveGraphEngine.train\u001b[0;34m(self, train_data, val_data, epochs, eval_every, eval_train, eval_val, callbacks, metrics, gpu, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_iterator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    139\u001b[0m item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 140\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_callbacks(\n\u001b[1;32m    143\u001b[0m     train_callbacks, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m, _strip_metrics(loss)\n\u001b[1;32m    144\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/Graph-Posterior-Network/gpn/nn/transductive_graph_engine.py:335\u001b[0m, in \u001b[0;36mTransductiveGraphEngine.train_batch\u001b[0;34m(self, data, optimizer, loss, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m loss(y_hat, data)\n\u001b[0;32m--> 335\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l_key, l_val \u001b[38;5;129;01min\u001b[39;00m loss_train\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gpn.experiments.multiple_run_experiment import MultipleRunExperiment\n",
    "from gpn.experiments.transductive_experiment import TransductiveExperiment\n",
    "from gpn.utils.config import (\n",
    "    DataConfiguration,\n",
    "    ModelConfiguration,\n",
    "    RunConfiguration,\n",
    "    TrainingConfiguration,\n",
    ")\n",
    "\n",
    "\n",
    "def create_experiment(model_name):\n",
    "    run_cfg = RunConfiguration(\n",
    "        job=\"train\",\n",
    "        eval_mode=\"default\",\n",
    "        experiment_directory=\"./.cache\",\n",
    "        save_model=True,\n",
    "        gpu=0,\n",
    "        experiment_name=\"ood_loc\",\n",
    "        num_inits=1,\n",
    "        num_splits=1,\n",
    "    )\n",
    "    data_cfg = DataConfiguration(\n",
    "        dataset=\"AmazonComputers\",\n",
    "        split_no=1,\n",
    "        root=\"./data\",\n",
    "        ood_flag=True,\n",
    "        train_samples_per_class=0.05,\n",
    "        val_samples_per_class=0.15,\n",
    "        test_samples_per_class=0.8,\n",
    "        split=\"random\",\n",
    "        ood_setting=\"poisoning\",\n",
    "        ood_type=\"leave_out_classes\",\n",
    "        ood_num_left_out_classes=-1,\n",
    "        ood_leave_out_last_classes=True,\n",
    "    )\n",
    "\n",
    "    model_cfg = ModelConfiguration(\n",
    "        model_name=model_name,\n",
    "        seed=42,\n",
    "        init_no=1,\n",
    "        dim_hidden=64,\n",
    "        dropout_prob=0.5,\n",
    "        K=10,\n",
    "        add_self_loops=True,\n",
    "        maf_layers=0,\n",
    "        gaussian_layers=0,\n",
    "        use_batched_flow=True,\n",
    "        loss_reduction=\"sum\",\n",
    "        approximate_reg=True,\n",
    "        flow_weight_decay=0.0,\n",
    "        pre_train_mode=\"flow\",\n",
    "        alpha_evidence_scale=\"latent-new\",\n",
    "        alpha_teleport=0.1,\n",
    "        entropy_reg=0.0001,\n",
    "        dim_latent=16,\n",
    "        radial_layers=10,\n",
    "        sparse_propagation=True,\n",
    "        sparse_x_prune_threshold=0.01\n",
    "    )\n",
    "\n",
    "    train_cfg = TrainingConfiguration(\n",
    "        epochs=100000,\n",
    "        stopping_mode=\"default\",\n",
    "        stopping_patience=50,\n",
    "        stopping_restore_best=True,\n",
    "        stopping_metric=\"val_CE\",\n",
    "        stopping_minimize=True,\n",
    "        finetune_epochs=0,\n",
    "        warmup_epochs=5,\n",
    "        lr=0.01,\n",
    "        weight_decay=0.001,\n",
    "    )\n",
    "\n",
    "    return MultipleRunExperiment(run_cfg, data_cfg, model_cfg, train_cfg)\n",
    "\n",
    "\n",
    "# gpn_e = create_experiment(\"GPN\")\n",
    "lop_e = create_experiment(\"GPN_LOP\")\n",
    "res_lop = lop_e.run()\n",
    "# res = gpn_e.run()\n",
    "res_lop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gpn.utils.utils import results_dict_to_df\n",
    "\n",
    "df_lop = results_dict_to_df(res_lop)\n",
    "df = results_dict_to_df(res)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "(pd.DataFrame(\n",
    "    dict(\n",
    "        val_gpn=df[\"val\"],\n",
    "        test_gpn=df[\"test\"],\n",
    "        val_lop=df_lop[\"val\"],\n",
    "        test_lop=df_lop[\"test\"],\n",
    "    )\n",
    ")).round(4).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpn.data.dataset_manager import DatasetManager\n",
    "from gpn.data.dataset_provider import InMemoryDatasetProvider\n",
    "import torch_sparse as ts\n",
    "\n",
    "ds = InMemoryDatasetProvider(\n",
    "    DatasetManager(\n",
    "        dataset=\"AmazonPhotos\",\n",
    "        split_no=1,\n",
    "        root=\"./data\",\n",
    "        ood_flag=True,\n",
    "        train_samples_per_class=0.05,\n",
    "        val_samples_per_class=0.15,\n",
    "        test_samples_per_class=0.8,\n",
    "        split=\"random\",\n",
    "        ood_setting=\"poisoning\",\n",
    "        ood_type=\"leave_out_classes\",\n",
    "        ood_num_left_out_classes=-1,\n",
    "        ood_leave_out_last_classes=True,\n",
    "    )\n",
    ").to_sparse()\n",
    "\n",
    "batch = list(ds.loader())[0]\n",
    "\n",
    "batch.adj_t.dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = batch.x.shape[0]\n",
    "adj_t = batch.adj_t.cuda()\n",
    "adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.0000, 1.0000, 0.0000],\n",
       "        [0.1000, 2.0000, 0.1000],\n",
       "        [0.0000, 0.0100, 3.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_sparse as ts\n",
    "\n",
    "adj_t = ts.SparseTensor.from_dense(\n",
    "    torch.Tensor([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
    ").cuda()\n",
    "x = torch.Tensor([1, 10, 100]).view(-1, 1).cuda()\n",
    "N = x.shape[0]\n",
    "adj_t /= x\n",
    "print(adj_t.dtype())\n",
    "adj_t.set_diag(torch.tensor([6,2,3], dtype=torch.float32).cuda()).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([0, 1, 1, 2], device='cuda:0'),\n",
      "             col=tensor([1, 0, 2, 1], device='cuda:0'),\n",
      "             val=tensor([1., 1., 1., 1.], device='cuda:0'),\n",
      "             size=(3, 3), nnz=4, density=44.44%) torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpn.layers.appnp_propagation import APPNPPropagation\n",
    "\n",
    "prop = APPNPPropagation(1, 0, 0, normalization=None)\n",
    "# x = torch.diag(torch.ones(N, device=\"cuda\"))\n",
    "x = ts.SparseTensor.eye(N, dtype=torch.float32, device=\"cuda\")  # type: ignore\n",
    "\n",
    "p: ts.SparseTensor = prop(x, adj_t)\n",
    "\n",
    "p.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.SparseTensor.from_edge_index(torch.tensor([[0,1],[0,1]]),sparse_sizes=(10,3)).dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparseTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "ts.SparseTensor.from_.get_diag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
