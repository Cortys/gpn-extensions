{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.datasets as pygd\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.8846153616905212,\n",
       " 'test_brier_score': 0.2654133439064026,\n",
       " 'test_ECE': 0.049611061811447144,\n",
       " 'test_confidence_aleatoric_apr': 0.9753641377962643,\n",
       " 'test_confidence_epistemic_apr': 0.9443021636961896,\n",
       " 'test_confidence_structure_apr': nan,\n",
       " 'test_confidence_aleatoric_auroc': 0.854986248695997,\n",
       " 'test_confidence_epistemic_auroc': 0.7357076964194881,\n",
       " 'test_confidence_structure_auroc': nan,\n",
       " 'test_CE': 0.3521946966648102,\n",
       " 'test_avg_prediction_confidence_aleatoric': 0.8350043296813965,\n",
       " 'test_avg_prediction_confidence_epistemic': 1082112.75,\n",
       " 'test_avg_sample_confidence_aleatoric': 0.8350043296813965,\n",
       " 'test_avg_sample_confidence_epistemic': 1135408.5,\n",
       " 'test_avg_sample_confidence_epistemic_entropy': 21.67955780029297,\n",
       " 'test_avg_sample_confidence_features': 815335.125,\n",
       " 'test_avg_sample_confidence_neighborhood': nan,\n",
       " 'test_average_entropy': 0.442186564207077,\n",
       " 'test_ood_detection_aleatoric_apr': 0.7680342911053363,\n",
       " 'test_ood_detection_aleatoric_auroc': 0.8397683897263375,\n",
       " 'test_ood_detection_epistemic_apr': 0.7865985945881573,\n",
       " 'test_ood_detection_epistemic_auroc': 0.8136744948351341,\n",
       " 'test_ood_detection_epistemic_entropy_apr': 0.8608783530622495,\n",
       " 'test_ood_detection_epistemic_entropy_auroc': 0.8785587975243148,\n",
       " 'test_ood_detection_features_apr': 0.7219168245171235,\n",
       " 'test_ood_detection_features_auroc': 0.7870651916068231,\n",
       " 'test_ood_detection_neighborhood_apr': nan,\n",
       " 'test_ood_detection_neighborhood_auroc': nan,\n",
       " 'test_ood_detection_structure_apr': nan,\n",
       " 'test_ood_detection_structure_auroc': nan,\n",
       " 'test_ood_accuracy': 0.0,\n",
       " 'test_ood_avg_prediction_confidence_aleatoric': 0.5830482840538025,\n",
       " 'test_ood_avg_prediction_confidence_epistemic': 201899.765625,\n",
       " 'test_ood_avg_sample_confidence_aleatoric': 0.5830482840538025,\n",
       " 'test_ood_avg_sample_confidence_epistemic': 256566.546875,\n",
       " 'test_ood_avg_sample_confidence_epistemic_entropy': 14.88781452178955,\n",
       " 'test_ood_avg_sample_confidence_neighborhood': nan,\n",
       " 'test_ood_avg_sample_confidence_features': 129945.15625,\n",
       " 'test_ood_average_entropy': 0.983461856842041,\n",
       " 'test_id_accuracy': 0.8846153616905212,\n",
       " 'test_id_avg_prediction_confidence_aleatoric': 0.8350043296813965,\n",
       " 'test_id_avg_prediction_confidence_epistemic': 1082112.75,\n",
       " 'test_id_avg_sample_confidence_aleatoric': 0.8350043296813965,\n",
       " 'test_id_avg_sample_confidence_epistemic': 1135408.5,\n",
       " 'test_id_avg_sample_confidence_epistemic_entropy': 21.67955780029297,\n",
       " 'test_id_avg_sample_confidence_features': 815335.125,\n",
       " 'test_id_average_entropy': 0.442186564207077,\n",
       " 'val_accuracy': 0.8717948794364929,\n",
       " 'val_brier_score': 0.291916161775589,\n",
       " 'val_ECE': 0.06474756449460983,\n",
       " 'val_confidence_aleatoric_apr': 0.9481314627074906,\n",
       " 'val_confidence_epistemic_apr': 0.9303440722012737,\n",
       " 'val_confidence_structure_apr': nan,\n",
       " 'val_confidence_aleatoric_auroc': 0.7776143790849673,\n",
       " 'val_confidence_epistemic_auroc': 0.6955882352941177,\n",
       " 'val_confidence_structure_auroc': nan,\n",
       " 'val_CE': 0.4251001477241516,\n",
       " 'val_avg_prediction_confidence_aleatoric': 0.8278400897979736,\n",
       " 'val_avg_prediction_confidence_epistemic': 1055091.75,\n",
       " 'val_avg_sample_confidence_aleatoric': 0.8278400897979736,\n",
       " 'val_avg_sample_confidence_epistemic': 1100588.25,\n",
       " 'val_avg_sample_confidence_epistemic_entropy': 21.783863067626953,\n",
       " 'val_avg_sample_confidence_features': 881474.4375,\n",
       " 'val_avg_sample_confidence_neighborhood': nan,\n",
       " 'val_average_entropy': 0.4597605764865875,\n",
       " 'val_ood_detection_aleatoric_apr': 0.7525623785030051,\n",
       " 'val_ood_detection_aleatoric_auroc': 0.8344073029936904,\n",
       " 'val_ood_detection_epistemic_apr': 0.795781743267768,\n",
       " 'val_ood_detection_epistemic_auroc': 0.8323936098805209,\n",
       " 'val_ood_detection_epistemic_entropy_apr': 0.8807900697114697,\n",
       " 'val_ood_detection_epistemic_entropy_auroc': 0.8928267776435316,\n",
       " 'val_ood_detection_features_apr': 0.7480002692089553,\n",
       " 'val_ood_detection_features_auroc': 0.804179531928223,\n",
       " 'val_ood_detection_neighborhood_apr': nan,\n",
       " 'val_ood_detection_neighborhood_auroc': nan,\n",
       " 'val_ood_detection_structure_apr': nan,\n",
       " 'val_ood_detection_structure_auroc': nan,\n",
       " 'val_ood_accuracy': 0.0,\n",
       " 'val_ood_avg_prediction_confidence_aleatoric': 0.5831719040870667,\n",
       " 'val_ood_avg_prediction_confidence_epistemic': 144300.71875,\n",
       " 'val_ood_avg_sample_confidence_aleatoric': 0.5831719040870667,\n",
       " 'val_ood_avg_sample_confidence_epistemic': 188227.515625,\n",
       " 'val_ood_avg_sample_confidence_epistemic_entropy': 14.704573631286621,\n",
       " 'val_ood_avg_sample_confidence_neighborhood': nan,\n",
       " 'val_ood_avg_sample_confidence_features': 87416.515625,\n",
       " 'val_ood_average_entropy': 0.9831030368804932,\n",
       " 'val_id_accuracy': 0.8717948794364929,\n",
       " 'val_id_avg_prediction_confidence_aleatoric': 0.8278400897979736,\n",
       " 'val_id_avg_prediction_confidence_epistemic': 1055091.75,\n",
       " 'val_id_avg_sample_confidence_aleatoric': 0.8278400897979736,\n",
       " 'val_id_avg_sample_confidence_epistemic': 1100588.25,\n",
       " 'val_id_avg_sample_confidence_epistemic_entropy': 21.783863067626953,\n",
       " 'val_id_avg_sample_confidence_features': 881474.4375,\n",
       " 'val_id_average_entropy': 0.4597605764865875}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpn.experiments.multiple_run_experiment import MultipleRunExperiment\n",
    "from gpn.experiments.transductive_experiment import TransductiveExperiment\n",
    "from gpn.utils.config import (\n",
    "    DataConfiguration,\n",
    "    ModelConfiguration,\n",
    "    RunConfiguration,\n",
    "    TrainingConfiguration,\n",
    ")\n",
    "\n",
    "\n",
    "def create_experiment(model_name):\n",
    "    run_cfg = RunConfiguration(\n",
    "        job=\"train\",\n",
    "        eval_mode=\"default\",\n",
    "        experiment_directory=\"./.cache\",\n",
    "        save_model=True,\n",
    "        gpu=0,\n",
    "        experiment_name=\"ood_loc\",\n",
    "        num_inits=1,\n",
    "        num_splits=1,\n",
    "    )\n",
    "    data_cfg = DataConfiguration(\n",
    "        dataset=\"CoraML\",\n",
    "        split_no=1,\n",
    "        root=\"./data\",\n",
    "        ood_flag=True,\n",
    "        train_samples_per_class=0.05,\n",
    "        val_samples_per_class=0.15,\n",
    "        test_samples_per_class=0.8,\n",
    "        split=\"random\",\n",
    "        ood_setting=\"poisoning\",\n",
    "        ood_type=\"leave_out_classes\",\n",
    "        ood_num_left_out_classes=-1,\n",
    "        ood_leave_out_last_classes=True,\n",
    "    )\n",
    "\n",
    "    model_cfg = ModelConfiguration(\n",
    "        model_name=model_name,\n",
    "        seed=42,\n",
    "        init_no=1,\n",
    "        dim_hidden=64,\n",
    "        dropout_prob=0.5,\n",
    "        K=10,\n",
    "        add_self_loops=True,\n",
    "        maf_layers=0,\n",
    "        gaussian_layers=0,\n",
    "        use_batched_flow=True,\n",
    "        loss_reduction=\"sum\",\n",
    "        approximate_reg=True,\n",
    "        flow_weight_decay=0.0,\n",
    "        pre_train_mode=\"flow\",\n",
    "        alpha_evidence_scale=\"latent-new\",\n",
    "        alpha_teleport=0.1,\n",
    "        entropy_reg=0.0001,\n",
    "        dim_latent=16,\n",
    "        radial_layers=10,\n",
    "        sparse_propagation=True,\n",
    "        sparse_x_prune_threshold=0.01\n",
    "    )\n",
    "\n",
    "    train_cfg = TrainingConfiguration(\n",
    "        epochs=100000,\n",
    "        stopping_mode=\"default\",\n",
    "        stopping_patience=50,\n",
    "        stopping_restore_best=True,\n",
    "        stopping_metric=\"val_CE\",\n",
    "        stopping_minimize=True,\n",
    "        finetune_epochs=0,\n",
    "        warmup_epochs=5,\n",
    "        lr=0.01,\n",
    "        weight_decay=0.001,\n",
    "    )\n",
    "\n",
    "    return MultipleRunExperiment(run_cfg, data_cfg, model_cfg, train_cfg)\n",
    "\n",
    "\n",
    "gpn_e = create_experiment(\"GPN\")\n",
    "lop_e = create_experiment(\"GPN_LOP\")\n",
    "res_lop = lop_e.run()\n",
    "res = gpn_e.run()\n",
    "res_lop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gpn.utils.utils import results_dict_to_df\n",
    "\n",
    "df_lop = results_dict_to_df(res_lop)\n",
    "df = results_dict_to_df(res)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "(pd.DataFrame(\n",
    "    dict(\n",
    "        val_gpn=df[\"val\"],\n",
    "        test_gpn=df[\"test\"],\n",
    "        val_lop=df_lop[\"val\"],\n",
    "        test_lop=df_lop[\"test\"],\n",
    "    )\n",
    ")).round(4).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpn.data.dataset_manager import DatasetManager\n",
    "from gpn.data.dataset_provider import InMemoryDatasetProvider\n",
    "import torch_sparse as ts\n",
    "\n",
    "ds = InMemoryDatasetProvider(\n",
    "    DatasetManager(\n",
    "        dataset=\"AmazonPhotos\",\n",
    "        split_no=1,\n",
    "        root=\"./data\",\n",
    "        ood_flag=True,\n",
    "        train_samples_per_class=0.05,\n",
    "        val_samples_per_class=0.15,\n",
    "        test_samples_per_class=0.8,\n",
    "        split=\"random\",\n",
    "        ood_setting=\"poisoning\",\n",
    "        ood_type=\"leave_out_classes\",\n",
    "        ood_num_left_out_classes=-1,\n",
    "        ood_leave_out_last_classes=True,\n",
    "    )\n",
    ").to_sparse()\n",
    "\n",
    "batch = list(ds.loader())[0]\n",
    "\n",
    "batch.adj_t.dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = batch.x.shape[0]\n",
    "adj_t = batch.adj_t.cuda()\n",
    "adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.0000, 1.0000, 0.0000],\n",
       "        [0.1000, 2.0000, 0.1000],\n",
       "        [0.0000, 0.0100, 3.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_sparse as ts\n",
    "\n",
    "adj_t = ts.SparseTensor.from_dense(\n",
    "    torch.Tensor([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
    ").cuda()\n",
    "x = torch.Tensor([1, 10, 100]).view(-1, 1).cuda()\n",
    "N = x.shape[0]\n",
    "adj_t /= x\n",
    "print(adj_t.dtype())\n",
    "adj_t.set_diag(torch.tensor([6,2,3], dtype=torch.float32).cuda()).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.6455, 0.0000],\n",
       "        [0.0645, 0.8333, 0.0908],\n",
       "        [0.0000, 0.0091, 0.9901]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpn.layers.appnp_propagation import APPNPPropagation\n",
    "\n",
    "prop = APPNPPropagation(1, 0, 0, normalization=\"sym\")\n",
    "x = ts.SparseTensor.eye(N, dtype=torch.float32, device=\"cuda\")  # type: ignore\n",
    "\n",
    "p: ts.SparseTensor = prop(x, adj_t)\n",
    "\n",
    "p.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.6455, 0.0000],\n",
       "        [0.0645, 0.8333, 0.0908],\n",
       "        [0.0000, 0.0091, 0.9901]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = APPNPPropagation(1, 0, 0, normalization=\"sym\")\n",
    "x = torch.diag(torch.ones(N, device=\"cuda\"))\n",
    "\n",
    "p: ts.SparseTensor = prop(x, adj_t)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.SparseTensor.from_edge_index(torch.tensor([[0,1],[0,1]]),sparse_sizes=(10,3)).dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparseTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "ts.SparseTensor.from_.get_diag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
